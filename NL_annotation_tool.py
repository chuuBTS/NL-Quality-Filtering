import streamlit as st
import json
import glob
import os
import pandas as pd

# è¯»å–æ‰€æœ‰ä»¥ .json ç»“å°¾çš„æ–‡ä»¶
result_files = glob.glob("./generated_nl_gpt_json/*.json")

# è·å–æ–‡ä»¶ååˆ—è¡¨
result_names = [os.path.basename(file) for file in result_files]

# åˆå§‹åŒ–æ–‡ä»¶ç´¢å¼•
if 'file_index' not in st.session_state:
    st.session_state.file_index = 0

if 'error_message' not in st.session_state:
    st.session_state.error_message = ''

def update_index():
    input_file = st.session_state.input_file
    if input_file in result_names:
        st.session_state.file_index = result_names.index(input_file)
        st.session_state.error_message = ''
    else:
        st.session_state.error_message = 'File not found!'

# é¡µé¢æ ‡é¢˜å’Œå¸®åŠ©ä¿¡æ¯
st.title('NL Quality Filtering')
st.caption("Please carefully review the NL Utterance to ensure it accurately includes all relevant information.")
# æ·»åŠ æ¨ªçº¿
st.markdown(
    """
    <style>
    hr.custom-hr {
        margin-top: 0px;
        margin-bottom: 20px;
    }
    </style>
    <hr class="custom-hr">
    """, 
    unsafe_allow_html=True
)

# ä¾§è¾¹æ å¤„ç†æ–‡ä»¶é€‰æ‹©
with st.sidebar:
    # å¤„ç†æ–‡ä»¶é€‰æ‹©
    selected_file = st.selectbox('Select or enter a filename:', result_names, index=st.session_state.file_index, key='input_file')
    st.session_state.file_index = result_names.index(selected_file)
    
    # æ˜¾ç¤ºå½“å‰æ–‡ä»¶ä½ç½®
    st.write(f"Currently viewing: <strong>{st.session_state.file_index + 1}/{len(result_names)}</strong>", unsafe_allow_html=True)
    
# ç¿»é¡µ
col1, col2, col3 = st.columns([1.5, 5.6, 1])
with col1:
    if st.button('â¬… Previous'):
        st.session_state.file_index = (st.session_state.file_index - 1) % len(result_files)
        st.session_state.error_message = ''
with col3:
    if st.button('Next â'):
        st.session_state.file_index = (st.session_state.file_index + 1) % len(result_files)
        st.session_state.error_message = ''

# è·å–å½“å‰æ–‡ä»¶è·¯å¾„
current_file = result_files[st.session_state.file_index]

# åŠ è½½å½“å‰æ–‡ä»¶çš„ JSON æ•°æ®
with open(current_file, 'r') as file:
    result_json = json.load(file)

# åŠ è½½å¦ä¸€ä¸ªç›®å½•ä¸­çš„åŒåæ–‡ä»¶ä»¥ç»Ÿè®¡chartsæ•°é‡
corresponding_file = f"./upload_dataset_task_1_new/{os.path.basename(current_file)}"
if os.path.exists(corresponding_file):
    with open(corresponding_file, 'r') as file:
        corresponding_json = json.load(file)
    chart_count = len(corresponding_json.get("generated_chart_list", []))
else:
    chart_count = 0

left, right = st.columns([2,1])

with left:
    # å±•ç¤º nl_utterance
    st.subheader("NL Utterance")
    st.info(f"""{result_json["gpt_result"]["nl_utterance"]}""")

with right:
    container = st.container(border=True)
# container.write(f'<p style="font-size:18px; ">{result_json["gpt_result"]["nl_utterance"]}</p>', unsafe_allow_html=True)

# æ·»åŠ å•é€‰æ¡†
quality_options = ["Good", "Average", "Poor", "Not Labeled"]
# åªåœ¨åˆå§‹åŠ è½½æ—¶è®¾ç½® current_quality
if 'current_quality' not in st.session_state:
    st.session_state.current_quality = result_json.get("quality_label", "Not Labeled")
selected_quality = container.radio("Quality Label", quality_options, index=quality_options.index(st.session_state.current_quality))

if selected_quality != st.session_state.current_quality:
    if selected_quality == "Not Labeled":
        result_json.pop("quality_label", None)
    else:
        result_json["quality_label"] = selected_quality
    with open(current_file, 'w') as file:
        json.dump(result_json, file, indent=4)
    st.toast(f'Quality labeled as {selected_quality} successfully!', icon='ğŸ‰')
    
st.subheader("relevant information")
# å±•ç¤ºå¯¹åº”chartsçš„æ•°é‡
st.markdown(f'<p style="font-size:18px; font-style:italic;">Number of charts: {chart_count}</p>', unsafe_allow_html=True)

# åˆ›å»ºæ ‡ç­¾é¡µ
tab1, tab2, tab3 = st.tabs(["Encoded Fields", "Transform Constraints", "Mark Constraints"])

with tab1:
    # æå–å¹¶å±•ç¤º encoded_fields è¡¨æ ¼
    encoded_fields_data = [
        {"field": field["field"], "nl_ref_phrase": field["nl_ref_phrase"]}
        for field in result_json["gpt_result"]["encoded_fields"]
    ]
    encoded_fields_df = pd.DataFrame(encoded_fields_data)
    # st.markdown('<p style="font-size:20px; font-style:italic;">Encoded Fields:</p>', unsafe_allow_html=True)
    st.table(encoded_fields_df)

with tab2:
    # æå–å¹¶å±•ç¤º transform è¡¨æ ¼
    transform_data = []
    for constraint in result_json["gpt_result"]["constraints"]:
        if constraint["c_type"] == "transform":
            other_info = []
            for item in constraint["c_list"]:
                if "oneOf" in item:
                    other_info.extend(item["oneOf"])
                if "aggregate" in item:
                    other_info.append(item["aggregate"])
                if "order" in item:
                    other_info.append(item["order"])
            transform_data.append({
                "c_name": constraint["c_name"],
                "field": item.get("field", "N/A"),
                "other_info": ", ".join(other_info),
                "nl_ref_phrase": constraint["nl_ref_phrase"]
            })

    transform_df = pd.DataFrame(transform_data)
    # st.markdown('<p style="font-size:20px; font-style:italic;">Transform Constraints:</p>', unsafe_allow_html=True)
    st.table(transform_df)

with tab3:
    # æå–å¹¶å±•ç¤º mark è¡¨æ ¼
    mark_data = [
        {"c_name": constraint["c_name"], "nl_ref_phrase": constraint["nl_ref_phrase"]}
        for constraint in result_json["gpt_result"]["constraints"]
        if constraint["c_type"] == "mark"
    ]
    mark_df = pd.DataFrame(mark_data)
    # st.markdown('<p style="font-size:20px; font-style:italic;">Mark Constraints:</p>', unsafe_allow_html=True)
    st.table(mark_df)

