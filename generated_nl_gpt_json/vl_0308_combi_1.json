{
  "gpt_result": {
    "nl_utterance": "Plot the average value over time.",
    "encoded_fields": [
      {
        "field": "value.average",
        "type": "quantitative",
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "average value"
      }
    ],
    "constraints": []
  },
  "input": "Dataset Information: {\n  \"data samples\": [\n    {\n      \"time\": \"{'interval_start': '2018-12-31T00:00:00Z', 'max': '2019-01-06T13:05:41.560000Z', 'min': '2019-01-01T11:18:35.384000Z'}\",\n      \"value\": \"{'average': 0.033399107154636, 'count': 1050, 'max': 0.037315417081117006, 'min': 0.030083676800131003, 'standard deviation': 0.001193542699587}\"\n    },\n    {\n      \"time\": \"{'interval_start': '2020-07-13T00:00:00Z', 'max': '2020-07-19T13:05:22.261000Z', 'min': '2020-07-13T11:36:01.132000Z'}\",\n      \"value\": \"{'average': 0.026411349902556003, 'count': 1553, 'max': 0.034105647355318, 'min': 0.020244358107447003, 'standard deviation': 0.001955636942698}\"\n    },\n    {\n      \"time\": \"{'interval_start': '2019-06-03T00:00:00Z', 'max': '2019-06-09T13:17:57.682000Z', 'min': '2019-06-03T11:48:23.615000Z'}\",\n      \"value\": \"{'average': 0.029501349743204, 'count': 1469, 'max': 0.044288370758295004, 'min': 0.022165885195136, 'standard deviation': 0.002488553579032}\"\n    },\n    {\n      \"time\": \"{'interval_start': '2021-02-22T00:00:00Z', 'max': '2021-02-28T14:05:35.662000Z', 'min': '2021-02-22T14:15:59.224000Z'}\",\n      \"value\": \"{'average': 0.034655258799275, 'count': 987, 'max': 0.040515702217817, 'min': 0.024205369874835, 'standard deviation': 0.0031374399719210004}\"\n    },\n    {\n      \"time\": \"{'interval_start': '2021-04-19T00:00:00Z', 'max': '2021-04-25T15:56:02.079000Z', 'min': '2021-04-19T16:06:26.582000Z'}\",\n      \"value\": \"{'average': 0.037302931991237, 'count': 1157, 'max': 0.044368688017129, 'min': 0.032205328345298004, 'standard deviation': 0.001484062065601}\"\n    }\n  ],\n  \"column names\": [\n    \"time\",\n    \"value\"\n  ]\n}\n\nYour Job:\nI am developing a NL to Data Visualization Dataset. \nPlease help me generate natural language utterance for given dataset and constraints.\nDefinition about the Taks:\n- 'utterance' is what a user would say to make a chart.  One NL 'utterance' is in one or two sentences. Here are two examples from Others for reference:\n    Trend for average horsepower over time across different origin.\n    scatter(x=production budget, y=worldwide gross) for content rating.\n- 'given dataset' is in form of column names, column type, range/unique values of the column.\n- 'constraints' are information about the chart that should be included in the utterance. \n    So we can find a reference phrase in the NL utterance that corresponds to the given constraints. \n- 'reference phrase' can be explicit, ambiguous, and by_value. 'ambiguous' means the phrase can map to more than one columns in the dataset, always a hypernym of column names(depending on the dataset values).\n    For example:\n    {\"column\": \"gdpPercap\", \"nl_ref_type\": \"explicit\", \"nl_ref_phrase\": \"GDP per capita\"},\n    {\"column\": [\"country\",\"continent\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"region\"}\n    {\"column\": [\"country\",\"country_short_name\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"countries\"}\n    {\"c_type\": \"mark\", \"c_name\": \"point chart\", \"nl_ref_type\": \"explicit\", \"nl_ref_phrase\": \"scatter plot\"}\n    {\"c_type\": \"mark\", \"c_name\": \"arc chart\", \"nl_ref_type\": \"explicit\", \"nl_ref_phrase\": \"pie chart\"}\n    {\"c_type\": \"transform\",\"c_name\": \"filter\",\"c_list\": [{\"field\": \"country\",\"oneOf\": [\"Iceland\",\"Norway\"]}],\"nl_ref_type\": \"explicit\",\"nl_ref_phrase\": \"for countries Iceland and Norway\"},\n    {\"c_type\": \"transform\",\"c_name\": \"filter\",\"c_list\": [{\"field\": \"country\",\"oneOf\": [\"Iceland\",\"Norway\"]}],\"nl_ref_type\": \"by_value\",\"nl_ref_phrase\": \"for Iceland and Norway\"},\n- the 'nl_ref_phrase' for 'ambiguous' columns should be equally near all ambiguous columns, not too near to one of the column since it would not be ambiguous.\n    good example: {\"column\": [\"country\",\"region\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"location\"}\n    bad example: {\"column\": [\"country\",\"region\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"region\"}\n- You only include given constraints and no other information. \n    For example, if a column name is not in the given constraint, it will not be included in the NL utterance.\n    Also, it a chart mark or chart encoding channel is not in the given constraint, it will not be included in the NL utterance.\n- all 'nl_ref_phrase' shoule be included in the 'nl_utterance'. \n\nThe output format is identical to the input format, but fill in the str blanks(\"...\").\n### Input:\n{\n  \"nl_utterance\": \"...\",\n  \"encoded_fields\": [\n    {\n      \"field\": \"value.average\",\n      \"type\": \"quantitative\",\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    }\n  ],\n  \"constraints\": []\n}\n\n### Output:"
}