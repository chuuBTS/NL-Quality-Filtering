{
  "gpt_result": {
    "nl_utterance": "What is the average value at the start of each time interval?",
    "encoded_fields": [
      {
        "field": "time.interval_start",
        "type": "temporal",
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "start of each time interval"
      },
      {
        "field": "value.average",
        "type": "quantitative",
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "average value"
      }
    ],
    "constraints": []
  },
  "input": "Dataset Information: {\n  \"data samples\": [\n    {\n      \"time\": \"{'interval_start': '2018-12-31T00:00:00Z', 'max': '2019-01-06T13:05:41.560000Z', 'min': '2019-01-01T11:18:35.384000Z'}\",\n      \"value\": \"{'average': 0.033399107154636, 'count': 1050, 'max': 0.037315417081117006, 'min': 0.030083676800131003, 'standard deviation': 0.001193542699587}\"\n    },\n    {\n      \"time\": \"{'interval_start': '2019-08-12T00:00:00Z', 'max': '2019-08-18T13:05:17.885000Z', 'min': '2019-08-12T11:35:55.859000Z'}\",\n      \"value\": \"{'average': 0.032014686813598, 'count': 1626, 'max': 0.03874135389924, 'min': 0.016050845384597, 'standard deviation': 0.0026273153090390004}\"\n    },\n    {\n      \"time\": \"{'interval_start': '2021-08-30T00:00:00Z', 'max': '2021-09-05T16:02:02.521000Z', 'min': '2021-08-30T16:12:34.839000Z'}\",\n      \"value\": \"{'average': 0.038105091611214004, 'count': 512, 'max': 0.049276076257228005, 'min': 0.031531915068626, 'standard deviation': 0.002770385849678}\"\n    },\n    {\n      \"time\": \"{'interval_start': '2019-02-25T00:00:00Z', 'max': '2019-03-03T13:56:41.536000Z', 'min': '2019-02-25T12:26:14.621000Z'}\",\n      \"value\": \"{'average': 0.034991697986428004, 'count': 1192, 'max': 0.04127774760127, 'min': 0.028600327670574, 'standard deviation': 0.001674754876185}\"\n    },\n    {\n      \"time\": \"{'interval_start': '2019-09-30T00:00:00Z', 'max': '2019-10-06T14:27:54.448000Z', 'min': '2019-09-30T11:17:54.445000Z'}\",\n      \"value\": \"{'average': 0.029016551946776003, 'count': 1272, 'max': 0.034746140241622, 'min': 0.022700043395161, 'standard deviation': 0.001882790363181}\"\n    }\n  ],\n  \"column names\": [\n    \"time\",\n    \"value\"\n  ]\n}\n\nYour Job:\nI am developing a NL to Data Visualization Dataset. \nPlease help me generate natural language utterance for given dataset and constraints.\nDefinition about the Taks:\n- 'utterance' is what a user would say to make a chart. It should be a questions structure. One NL 'utterance' is in one or two sentences. Here are two examples from Questions for reference:\n    What major genre had the highest average worldwide gross?\n    Which countries have the highest acceleration for cars of different cylinders?\n- 'given dataset' is in form of column names, column type, range/unique values of the column.\n- 'constraints' are information about the chart that should be included in the utterance. \n    So we can find a reference phrase in the NL utterance that corresponds to the given constraints. \n- 'reference phrase' can be explicit, ambiguous, and by_value. 'ambiguous' means the phrase can map to more than one columns in the dataset, always a hypernym of column names(depending on the dataset values).\n    For example:\n    {\"column\": \"gdpPercap\", \"nl_ref_type\": \"explicit\", \"nl_ref_phrase\": \"GDP per capita\"},\n    {\"column\": [\"country\",\"continent\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"region\"}\n    {\"column\": [\"country\",\"country_short_name\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"countries\"}\n    {\"c_type\": \"mark\", \"c_name\": \"point chart\", \"nl_ref_type\": \"explicit\", \"nl_ref_phrase\": \"scatter plot\"}\n    {\"c_type\": \"mark\", \"c_name\": \"arc chart\", \"nl_ref_type\": \"explicit\", \"nl_ref_phrase\": \"pie chart\"}\n    {\"c_type\": \"transform\",\"c_name\": \"filter\",\"c_list\": [{\"field\": \"country\",\"oneOf\": [\"Iceland\",\"Norway\"]}],\"nl_ref_type\": \"explicit\",\"nl_ref_phrase\": \"for countries Iceland and Norway\"},\n    {\"c_type\": \"transform\",\"c_name\": \"filter\",\"c_list\": [{\"field\": \"country\",\"oneOf\": [\"Iceland\",\"Norway\"]}],\"nl_ref_type\": \"by_value\",\"nl_ref_phrase\": \"for Iceland and Norway\"},\n- the 'nl_ref_phrase' for 'ambiguous' columns should be equally near all ambiguous columns, not too near to one of the column since it would not be ambiguous.\n    good example: {\"column\": [\"country\",\"region\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"location\"}\n    bad example: {\"column\": [\"country\",\"region\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"region\"}\n- You only include given constraints and no other information. \n    For example, if a column name is not in the given constraint, it will not be included in the NL utterance.\n    Also, it a chart mark or chart encoding channel is not in the given constraint, it will not be included in the NL utterance.\n- all 'nl_ref_phrase' shoule be included in the 'nl_utterance'. \n\nThe output format is identical to the input format, but fill in the str blanks(\"...\").\n### Input:\n{\n  \"nl_utterance\": \"...\",\n  \"encoded_fields\": [\n    {\n      \"field\": \"time.interval_start\",\n      \"type\": \"temporal\",\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    },\n    {\n      \"field\": \"value.average\",\n      \"type\": \"quantitative\",\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    }\n  ],\n  \"constraints\": []\n}\n\n### Output:"
}