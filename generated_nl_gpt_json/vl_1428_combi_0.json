{
  "gpt_result": {
    "nl_utterance": "Create a bar chart showing the sum of counts for each library and variant class, sorted by variant class in the order wildtype, synonymous, 1 nonsynonymous, >1 nonsynonymous, deletion, stop. Include the functional score as another axis.",
    "encoded_fields": [
      {
        "field": "library",
        "type": "nominal",
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "library"
      },
      {
        "field": "variant_class",
        "type": "nominal",
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "variant class"
      },
      {
        "field": "func_score",
        "type": "quantitative",
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "functional score"
      },
      {
        "field": "count",
        "type": "quantitative",
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "count"
      }
    ],
    "constraints": [
      {
        "c_type": "transform",
        "c_name": "aggregate",
        "c_list": [
          {
            "field": "count",
            "aggregate": "sum"
          }
        ],
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "sum of counts"
      },
      {
        "c_type": "transform",
        "c_name": "sort",
        "c_list": [
          [
            "wildtype",
            "synonymous",
            "1 nonsynonymous",
            ">1 nonsynonymous",
            "deletion",
            "stop"
          ]
        ],
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "sorted by variant class in the order wildtype, synonymous, 1 nonsynonymous, >1 nonsynonymous, deletion, stop"
      }
    ]
  },
  "input": "Dataset Information: {\n  \"data samples\": [\n    {\n      \"library\": \"Lib-1\",\n      \"variant_class\": \"1 nonsynonymous\",\n      \"func_score\": -11.6082,\n      \"count\": 1.0879177562792605e-05,\n      \"mean_func_score\": -0.382345700798838\n    },\n    {\n      \"library\": \"Lib-3\",\n      \"variant_class\": \"wildtype\",\n      \"func_score\": 4.849861224489796,\n      \"count\": 1.2101318816414541e-15,\n      \"mean_func_score\": -0.2417304290602789\n    },\n    {\n      \"library\": \"Lib-1\",\n      \"variant_class\": \"synonymous\",\n      \"func_score\": -10.145261224489795,\n      \"count\": 2.215505855865533e-17,\n      \"mean_func_score\": -0.163277628458498\n    },\n    {\n      \"library\": \"Lib-4\",\n      \"variant_class\": \">1 nonsynonymous\",\n      \"func_score\": -10.8767306122449,\n      \"count\": 0.0008843093948201,\n      \"mean_func_score\": -1.6098371530374345\n    },\n    {\n      \"library\": \"Lib-3\",\n      \"variant_class\": \"deletion\",\n      \"func_score\": 5.94706530612245,\n      \"count\": 2.1521163714694197e-12,\n      \"mean_func_score\": -2.6665383065429022\n    }\n  ],\n  \"column names\": [\n    \"library\",\n    \"variant_class\",\n    \"func_score\",\n    \"count\",\n    \"mean_func_score\"\n  ]\n}\n\nYour Job:\nI am developing a NL to Data Visualization Dataset. \nPlease help me generate natural language utterance for given dataset and constraints.\nDefinition about the Taks:\n- 'utterance' is what a user would say to make a chart.  One NL 'utterance' is in one or two sentences. Here are two examples from Others for reference:\n    scatter(x=production budget, y=worldwide gross) for content rating.\n    Trend for average horsepower over time across different origin.\n- 'given dataset' is in form of column names, column type, range/unique values of the column.\n- 'constraints' are information about the chart that should be included in the utterance. \n    So we can find a reference phrase in the NL utterance that corresponds to the given constraints. \n- 'reference phrase' can be explicit, ambiguous, and by_value. 'ambiguous' means the phrase can map to more than one columns in the dataset, always a hypernym of column names(depending on the dataset values).\n    For example:\n    {\"column\": \"gdpPercap\", \"nl_ref_type\": \"explicit\", \"nl_ref_phrase\": \"GDP per capita\"},\n    {\"column\": [\"country\",\"continent\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"region\"}\n    {\"column\": [\"country\",\"country_short_name\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"countries\"}\n    {\"c_type\": \"mark\", \"c_name\": \"point chart\", \"nl_ref_type\": \"explicit\", \"nl_ref_phrase\": \"scatter plot\"}\n    {\"c_type\": \"mark\", \"c_name\": \"arc chart\", \"nl_ref_type\": \"explicit\", \"nl_ref_phrase\": \"pie chart\"}\n    {\"c_type\": \"transform\",\"c_name\": \"filter\",\"c_list\": [{\"field\": \"country\",\"oneOf\": [\"Iceland\",\"Norway\"]}],\"nl_ref_type\": \"explicit\",\"nl_ref_phrase\": \"for countries Iceland and Norway\"},\n    {\"c_type\": \"transform\",\"c_name\": \"filter\",\"c_list\": [{\"field\": \"country\",\"oneOf\": [\"Iceland\",\"Norway\"]}],\"nl_ref_type\": \"by_value\",\"nl_ref_phrase\": \"for Iceland and Norway\"},\n- the 'nl_ref_phrase' for 'ambiguous' columns should be equally near all ambiguous columns, not too near to one of the column since it would not be ambiguous.\n    good example: {\"column\": [\"country\",\"region\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"location\"}\n    bad example: {\"column\": [\"country\",\"region\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"region\"}\n- You only include given constraints and no other information. \n    For example, if a column name is not in the given constraint, it will not be included in the NL utterance.\n    Also, it a chart mark or chart encoding channel is not in the given constraint, it will not be included in the NL utterance.\n- all 'nl_ref_phrase' shoule be included in the 'nl_utterance'. \n\nThe output format is identical to the input format, but fill in the str blanks(\"...\").\n### Input:\n{\n  \"nl_utterance\": \"...\",\n  \"encoded_fields\": [\n    {\n      \"field\": \"library\",\n      \"type\": \"nominal\",\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    },\n    {\n      \"field\": \"variant_class\",\n      \"type\": \"nominal\",\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    },\n    {\n      \"field\": \"func_score\",\n      \"type\": \"quantitative\",\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    },\n    {\n      \"field\": \"count\",\n      \"type\": \"quantitative\",\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    }\n  ],\n  \"constraints\": [\n    {\n      \"c_type\": \"transform\",\n      \"c_name\": \"aggregate\",\n      \"c_list\": [\n        {\n          \"field\": \"count\",\n          \"aggregate\": \"sum\"\n        }\n      ],\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    },\n    {\n      \"c_type\": \"transform\",\n      \"c_name\": \"sort\",\n      \"c_list\": [\n        [\n          \"wildtype\",\n          \"synonymous\",\n          \"1 nonsynonymous\",\n          \">1 nonsynonymous\",\n          \"deletion\",\n          \"stop\"\n        ]\n      ],\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    }\n  ]\n}\n\n### Output:"
}