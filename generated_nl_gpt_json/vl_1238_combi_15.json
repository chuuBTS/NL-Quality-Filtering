{
  "gpt_result": {
    "nl_utterance": "Show the trend of Total_billion over time.",
    "encoded_fields": [
      {
        "field": "Total_billion",
        "type": "quantitative",
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "Total_billion"
      }
    ],
    "constraints": [
      {
        "c_type": "task",
        "c_name": "trend",
        "c_list": [
          {
            "mark": [
              "bar",
              "line",
              "area"
            ],
            "encoding": {
              "x": {
                "type": "temporal"
              }
            }
          }
        ],
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "trend"
      }
    ]
  },
  "input": "Dataset Information: {\n  \"data samples\": [\n    {\n      \"Date\": \"08/31/2022\",\n      \"GRA Purchases\": 93769635059.0,\n      \"PRGT 1/2/\": 15254184552.0,\n      \"Totals\": 109023819611.0,\n      \"Year\": 2022.0,\n      \"Total_billion\": 109.0238196\n    },\n    {\n      \"Date\": \"12/31/2010\",\n      \"GRA Purchases\": 55620104510.0,\n      \"PRGT 1/2/\": 4819344134.0,\n      \"Totals\": 60439448644.0,\n      \"Year\": 2010.0,\n      \"Total_billion\": 60.43944864\n    },\n    {\n      \"Date\": \"12/31/2006\",\n      \"GRA Purchases\": 9822640239.0,\n      \"PRGT 1/2/\": 3844020520.0,\n      \"Totals\": 13666660759.0,\n      \"Year\": 2006.0,\n      \"Total_billion\": 13.66666076\n    },\n    {\n      \"Date\": \"12/31/2017\",\n      \"GRA Purchases\": 39585385873.0,\n      \"PRGT 1/2/\": 6522280669.0,\n      \"Totals\": 46107666542.0,\n      \"Year\": 2017.0,\n      \"Total_billion\": 46.10766654\n    },\n    {\n      \"Date\": \"12/31/1995\",\n      \"GRA Purchases\": 35929173412.0,\n      \"PRGT 1/2/\": 5657438528.0,\n      \"Totals\": 41586611940.0,\n      \"Year\": 1995.0,\n      \"Total_billion\": 41.58661194\n    }\n  ],\n  \"column names\": [\n    \"Date\",\n    \"GRA Purchases\",\n    \"PRGT 1/2/\",\n    \"Totals\",\n    \"Year\",\n    \"Total_billion\"\n  ]\n}\n\nYour Job:\nI am developing a NL to Data Visualization Dataset. \nPlease help me generate natural language utterance for given dataset and constraints.\nDefinition about the Taks:\n- 'utterance' is what a user would say to make a chart.  One NL 'utterance' is in one or two sentences. Here are two examples from Others for reference:\n    Trend for average horsepower over time across different origin.\n    I want to know how many orders there are by the quantity of the order.\n- 'given dataset' is in form of column names, column type, range/unique values of the column.\n- 'constraints' are information about the chart that should be included in the utterance. \n    So we can find a reference phrase in the NL utterance that corresponds to the given constraints. \n- 'reference phrase' can be explicit, ambiguous, and by_value. 'ambiguous' means the phrase can map to more than one columns in the dataset, always a hypernym of column names(depending on the dataset values).\n    For example:\n    {\"column\": \"gdpPercap\", \"nl_ref_type\": \"explicit\", \"nl_ref_phrase\": \"GDP per capita\"},\n    {\"column\": [\"country\",\"continent\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"region\"}\n    {\"column\": [\"country\",\"country_short_name\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"countries\"}\n    {\"c_type\": \"mark\", \"c_name\": \"point chart\", \"nl_ref_type\": \"explicit\", \"nl_ref_phrase\": \"scatter plot\"}\n    {\"c_type\": \"mark\", \"c_name\": \"arc chart\", \"nl_ref_type\": \"explicit\", \"nl_ref_phrase\": \"pie chart\"}\n    {\"c_type\": \"transform\",\"c_name\": \"filter\",\"c_list\": [{\"field\": \"country\",\"oneOf\": [\"Iceland\",\"Norway\"]}],\"nl_ref_type\": \"explicit\",\"nl_ref_phrase\": \"for countries Iceland and Norway\"},\n    {\"c_type\": \"transform\",\"c_name\": \"filter\",\"c_list\": [{\"field\": \"country\",\"oneOf\": [\"Iceland\",\"Norway\"]}],\"nl_ref_type\": \"by_value\",\"nl_ref_phrase\": \"for Iceland and Norway\"},\n- the 'nl_ref_phrase' for 'ambiguous' columns should be equally near all ambiguous columns, not too near to one of the column since it would not be ambiguous.\n    good example: {\"column\": [\"country\",\"region\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"location\"}\n    bad example: {\"column\": [\"country\",\"region\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"region\"}\n- You only include given constraints and no other information. \n    For example, if a column name is not in the given constraint, it will not be included in the NL utterance.\n    Also, it a chart mark or chart encoding channel is not in the given constraint, it will not be included in the NL utterance.\n- all 'nl_ref_phrase' shoule be included in the 'nl_utterance'. \n\nThe output format is identical to the input format, but fill in the str blanks(\"...\").\n### Input:\n{\n  \"nl_utterance\": \"...\",\n  \"encoded_fields\": [\n    {\n      \"field\": \"Total_billion\",\n      \"type\": \"quantitative\",\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    }\n  ],\n  \"constraints\": [\n    {\n      \"c_type\": \"task\",\n      \"c_name\": \"trend\",\n      \"c_list\": [\n        {\n          \"mark\": [\n            \"bar\",\n            \"line\",\n            \"area\"\n          ],\n          \"encoding\": {\n            \"x\": {\n              \"type\": \"temporal\"\n            }\n          }\n        }\n      ],\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    }\n  ]\n}\n\n### Output:"
}