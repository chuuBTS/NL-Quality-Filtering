{
  "gpt_result": {
    "nl_utterance": "Create a bar chart showing the functional score and count for each library and variant class, and sort the variant classes as wildtype, synonymous, 1 nonsynonymous, >1 nonsynonymous, deletion, and stop.",
    "encoded_fields": [
      {
        "field": "library",
        "type": "nominal",
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "each library"
      },
      {
        "field": "variant_class",
        "type": "nominal",
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "each variant class"
      },
      {
        "field": "func_score",
        "type": "quantitative",
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "functional score"
      },
      {
        "field": "count",
        "type": "quantitative",
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "count"
      }
    ],
    "constraints": [
      {
        "c_type": "transform",
        "c_name": "sort",
        "c_list": [
          [
            "wildtype",
            "synonymous",
            "1 nonsynonymous",
            ">1 nonsynonymous",
            "deletion",
            "stop"
          ]
        ],
        "nl_ref_type": "explicit",
        "nl_ref_phrase": "sort the variant classes as wildtype, synonymous, 1 nonsynonymous, >1 nonsynonymous, deletion, and stop"
      }
    ]
  },
  "input": "Dataset Information: {\n  \"data samples\": [\n    {\n      \"library\": \"Lib-1\",\n      \"variant_class\": \"1 nonsynonymous\",\n      \"func_score\": -11.4838,\n      \"count\": 3.868457626048094e-60,\n      \"mean_func_score\": -0.6787553364315222\n    },\n    {\n      \"library\": \"Lib-3\",\n      \"variant_class\": \"wildtype\",\n      \"func_score\": 3.06874081632653,\n      \"count\": 0.0004029530792303,\n      \"mean_func_score\": -0.1080560274655296\n    },\n    {\n      \"library\": \"Lib-2\",\n      \"variant_class\": \"wildtype\",\n      \"func_score\": 4.3623,\n      \"count\": 6.559069185522828e-23,\n      \"mean_func_score\": -0.1326304924049342\n    },\n    {\n      \"library\": \"Lib-3\",\n      \"variant_class\": \"deletion\",\n      \"func_score\": -2.752275510204081,\n      \"count\": 0.0766619791629708,\n      \"mean_func_score\": -2.2751206720233745\n    },\n    {\n      \"library\": \"Lib-3\",\n      \"variant_class\": \">1 nonsynonymous\",\n      \"func_score\": -3.3990551020408173,\n      \"count\": 0.0848657236704999,\n      \"mean_func_score\": -2.3235790600742487\n    }\n  ],\n  \"column names\": [\n    \"library\",\n    \"variant_class\",\n    \"func_score\",\n    \"count\",\n    \"mean_func_score\"\n  ]\n}\n\nYour Job:\nI am developing a NL to Data Visualization Dataset. \nPlease help me generate natural language utterance for given dataset and constraints.\nDefinition about the Taks:\n- 'utterance' is what a user would say to make a chart. It should be a commands structure. One NL 'utterance' is in one or two sentences. Here are two examples from Commands for reference:\n    Make the bars stacked with the ship status.\n    Draw a line chart of daily sales forecasts.\n- 'given dataset' is in form of column names, column type, range/unique values of the column.\n- 'constraints' are information about the chart that should be included in the utterance. \n    So we can find a reference phrase in the NL utterance that corresponds to the given constraints. \n- 'reference phrase' can be explicit, ambiguous, and by_value. 'ambiguous' means the phrase can map to more than one columns in the dataset, always a hypernym of column names(depending on the dataset values).\n    For example:\n    {\"column\": \"gdpPercap\", \"nl_ref_type\": \"explicit\", \"nl_ref_phrase\": \"GDP per capita\"},\n    {\"column\": [\"country\",\"continent\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"region\"}\n    {\"column\": [\"country\",\"country_short_name\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"countries\"}\n    {\"c_type\": \"mark\", \"c_name\": \"point chart\", \"nl_ref_type\": \"explicit\", \"nl_ref_phrase\": \"scatter plot\"}\n    {\"c_type\": \"mark\", \"c_name\": \"arc chart\", \"nl_ref_type\": \"explicit\", \"nl_ref_phrase\": \"pie chart\"}\n    {\"c_type\": \"transform\",\"c_name\": \"filter\",\"c_list\": [{\"field\": \"country\",\"oneOf\": [\"Iceland\",\"Norway\"]}],\"nl_ref_type\": \"explicit\",\"nl_ref_phrase\": \"for countries Iceland and Norway\"},\n    {\"c_type\": \"transform\",\"c_name\": \"filter\",\"c_list\": [{\"field\": \"country\",\"oneOf\": [\"Iceland\",\"Norway\"]}],\"nl_ref_type\": \"by_value\",\"nl_ref_phrase\": \"for Iceland and Norway\"},\n- the 'nl_ref_phrase' for 'ambiguous' columns should be equally near all ambiguous columns, not too near to one of the column since it would not be ambiguous.\n    good example: {\"column\": [\"country\",\"region\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"location\"}\n    bad example: {\"column\": [\"country\",\"region\"], \"nl_ref_type\": \"ambiguous\", \"nl_ref_phrase\": \"region\"}\n- You only include given constraints and no other information. \n    For example, if a column name is not in the given constraint, it will not be included in the NL utterance.\n    Also, it a chart mark or chart encoding channel is not in the given constraint, it will not be included in the NL utterance.\n- all 'nl_ref_phrase' shoule be included in the 'nl_utterance'. \n\nThe output format is identical to the input format, but fill in the str blanks(\"...\").\n### Input:\n{\n  \"nl_utterance\": \"...\",\n  \"encoded_fields\": [\n    {\n      \"field\": \"library\",\n      \"type\": \"nominal\",\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    },\n    {\n      \"field\": \"variant_class\",\n      \"type\": \"nominal\",\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    },\n    {\n      \"field\": \"func_score\",\n      \"type\": \"quantitative\",\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    },\n    {\n      \"field\": \"count\",\n      \"type\": \"quantitative\",\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    }\n  ],\n  \"constraints\": [\n    {\n      \"c_type\": \"transform\",\n      \"c_name\": \"sort\",\n      \"c_list\": [\n        [\n          \"wildtype\",\n          \"synonymous\",\n          \"1 nonsynonymous\",\n          \">1 nonsynonymous\",\n          \"deletion\",\n          \"stop\"\n        ]\n      ],\n      \"nl_ref_type\": \"explicit\",\n      \"nl_ref_phrase\": \"...\"\n    }\n  ]\n}\n\n### Output:"
}